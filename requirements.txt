# Core dependencies for QuickScribe dictation app
sounddevice
soundfile
numpy
pynput
python-dotenv
pyperclip
litellm
colorama

# Development and testing
pytest
pytest-asyncio

# VOSK dependencies (optional - for local speech recognition)
vosk

# HuggingFace transcription dependencies (optional - for local transcription models)
torch
transformers
huggingface_hub
phonemizer
pyrubberband

# Optional dependencies for specific HuggingFace models
sentencepiece  # Required for Speech2Text models (facebook/s2t-*)
bitsandbytes  # Required for quantized models (--model-id huggingface/model@4 or @8)
accelerate  # Required for device_map with quantized models

# llama.cpp dependencies (optional - for local GGUF models)
llama-cpp-python  # Required for llamacpp/gguf providers (--model llamacpp/repo@file.gguf)

# NeMo dependencies (optional - for NVIDIA NeMo ASR models)
nemo_toolkit[asr]  # Required for NeMo TDT models (--transcription-model huggingface/nvidia/parakeet-*)

# macOS dependencies for keyboard injection
pyobjc-core>=11.1; sys_platform == "darwin"
pyobjc-framework-Quartz>=11.1; sys_platform == "darwin"
pyobjc-framework-ApplicationServices>=11.1; sys_platform == "darwin"

# Windows dependencies for keyboard injection
pywin32; sys_platform == "win32"

# System dependencies (not installable via pip):
# xdotool - For Linux/FreeBSD keyboard injection
#   Install via: sudo apt-get install xdotool (Debian/Ubuntu)
#   Install via: sudo dnf install xdotool (Fedora/RHEL)

# Installation Notes:
# - Core functionality requires only the first 8 packages
# - VOSK is optional for local speech recognition (--transcription-model vosk/...)
# - HuggingFace deps are optional for local models (--transcription-model huggingface/...)
#   - Supports CTC models: Wav2Vec2, HuBERT (phoneme/text output)
#   - Supports Seq2Seq models: Whisper, Speech2Text (text output)
# - SentencePiece only needed for Speech2Text models (facebook/s2t-*)
# - llama-cpp-python for GGUF models (--model llamacpp/... or gguf/...)
#   - Install: CMAKE_ARGS="-DGGML_NATIVE=OFF" pip install llama-cpp-python
#   - For GPU support: CMAKE_ARGS="-DGGML_CUDA=on" pip install llama-cpp-python
# - PyTorch installation varies by platform, see: https://pytorch.org/get-started/
# - For CPU-only PyTorch: pip install torch --index-url https://download.pytorch.org/whl/cpu